# ğŸ® Video Highlights Detection API

This project provides an AI-powered backend and frontend to analyze videos, detect highlight moments using motion and brightness spikes, transcribe speech, and generate captions. Users can upload videos through the frontend interface, which communicates with the Flask backend API to return the processed results and visualizes them in a user-friendly format.

---

## ğŸ“ Project Structure

```
project-root/
â”‚
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ main.py               # Flask app and API routes
â”‚   â”‚               
â”‚   â”œâ”€â”€ uploaded_videos
â”‚   |___files     
â”‚   â””â”€â”€ requirements.txt
â”‚
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ upload.html               # Video upload interface
â”‚   â”œâ”€â”€ templates/play.html       # Results viewer page
â”‚   â”œâ”€â”€ static/                   # JS, CSS, images
â”‚
â”œâ”€â”€ .env                          # Environment variables
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md                     # Project documentation
```

---

## âœ¨ Features

- Upload videos via a simple frontend.
- Detect motion and brightness spikes using OpenCV.
- Transcribe speech using Whisper and generate human-readable captions.
- Analyze and combine audio + visual cues to detect highlights.
- Display key segments and captions in an interactive viewer.
- Show real-time upload and processing status using alerts and spinners.
- Persistent metadata via `sessionStorage` between pages.

---

## âš™ï¸ Prerequisites

- Python 3.9+
- pip
- html, bootstrap, css and javascript
- ffmpeg installed and added to your system PATH

---

## ğŸ¥ª Setup

### 1. Clone the repo

```bash
git clone https://github.com/your-username/video-highlights-api.git
cd video-highlights-api
```

### 2. Create and activate virtual environment

```bash
python3 -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

### 3. Install dependencies

```bash
cd backend
pip install -r requirements.txt
```

If using Whisper, make sure `ffmpeg` is installed globally:

```bash
brew install ffmpeg  # macOS

```

---

## ğŸ“¦ Environment Configuration

Create a `.env` file in the root directory:

### `.env`

```env
APP_URL=http://127.0.0.1:5000

```



---

## â–¶ï¸ Running the Project

### 1. Start the Flask API

```bash
cd backend
source ../venv/bin/activate
flask --app app/main.py run
```

By default, this runs at `http://127.0.0.1:5000`.

---

### 2. Open the Frontend

Open `frontend/upload.html` directly in your browser (you **donâ€™t** serve it from Flask).

Make sure:

- The upload form submits to `http://127.0.0.1:5000/upload`
- The response redirects to `play.html`, which reads metadata from `sessionStorage`

To ensure your `play.html` is accessible:

- It must be inside `frontend/`
- Do **not** move it to the Flask `templates/` folder unless you want Flask to render it

---

## ğŸ“¤ API Endpoint

### `POST /upload`

Uploads a video and returns metadata + highlights.

**Request:**

- `FormData` with one field: `video` (file input)

**Response:**

```json
{
  "filename": "example.mp4",
  "size_mb": 12.4,
  "duration": 145.2,
  "motion_spikes": [3.4, 6.7, ...],
  "captions": [
    "[0.0s - 4.0s] Hello world.",
    "[4.0s - 10.0s] Welcome to the video."
  ],
  "highlights": [
    {
      "start": 3.0,
      "end": 8.0,
      "text": "Exciting moment"
    }
  ],
  "audio_url": "/files/audio.wav"
}
```

---

## ğŸ› ï¸ Customization

- Replace `detect_motion_spikes`, `detect_bright_spikes`, and `transcribe_audio` with your own logic as needed.
- Customize the frontend in `upload.html` and `play.html` to match your branding.
- Adjust highlight generation thresholds in `transformer.py`.

